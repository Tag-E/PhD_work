{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from building_blocks_reader import bulding_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -e /wsgjsc/home/taggi1/workspace_folders/CorrelatorAnalyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mplStyle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasted from available code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import json\n",
    "import itertools\n",
    "import h5py as h5 \n",
    "import numpy as np\n",
    "import gvar as gv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "#sys.path.insert(1, '../../CorrelatorAnalyser')\n",
    "sys.path.insert(1, '/wsgjsc/home/taggi1/workspace_folders/CorrelatorAnalyser')\n",
    "\n",
    "\n",
    "import correlatoranalyser as ca\n",
    "\n",
    "#from lib_ensembleDetails import EnsembleDetails\n",
    "\n",
    "#from mplStyle import *\n",
    "\n",
    "# %matplotlib ipympl\n",
    "%matplotlib inline\n",
    "\n",
    "markers = [\".\",\"+\",\"^\",\"s\",\"p\",\"*\",\"h\",\"v\",\"x\",\"<\",\">\",\"D\",\"o\"]\n",
    "linestyles = ['solid', 'dotted', 'dashed', 'dashdot', (0,(1,10)), (5,(10,13))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with h5.File(\"Cache/D251_Nbst100.h5\", 'r') as h5f:\n",
    "#    params = json.loads(\n",
    "#        h5f[\"Meta\"][()]\n",
    "#    )\n",
    "\n",
    "# I want to adept some naming conventions\n",
    "params[\"C2pt fit\"] = {\n",
    "    \"shared\": {\n",
    "        \"min interval start\": 1,\n",
    "        \"interval end\"      : 50,\n",
    "        \"interval step\"     : 4,\n",
    "        \n",
    "        \"max number states\": 2,\n",
    "        \"model\" : \"sum of ordered exponentials\",\n",
    "        \n",
    "        \"central value fit\": True,            \n",
    "        \"central value fit correlated\": False, \n",
    "        \"resample fit\": True,     \n",
    "        \"resample fit correlated\": False,      \n",
    "        \"resample prior\": False,\n",
    "\n",
    "        \"prior strategy\": {\n",
    "            \"Eeff\": {\n",
    "                \"estimate range start\": 15,\n",
    "                \"estimate range stop\" : 50\n",
    "            },\n",
    "            \"std scale\": 3,\n",
    "            \"mpi\": gv.gvar(\"0.09203(16)\")\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m     E_eff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m( np\u001b[38;5;241m.\u001b[39mroll(logC, \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mroll(logC, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m ) )[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m E_eff\n\u001b[1;32m      8\u001b[0m Eeff_unpolarized \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: effective_energy(C2pt_unpolarized, q2)\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m q2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mparams\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximal momentum squared\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "def effective_energy(C2pt, q2):\n",
    "    logC = np.log(np.abs(C2pt[q2]))\n",
    "    \n",
    "    E_eff = 0.5*( np.roll(logC, +1, axis=-1) - np.roll(logC, -1, axis=-1 ) )[...,1:-1]\n",
    "\n",
    "    return E_eff\n",
    "\n",
    "#Eeff_unpolarized = {\n",
    "#    f\"q2: {q2}\": effective_energy(C2pt_unpolarized, q2)\n",
    "#        for q2 in range(params[\"maximal momentum squared\"]+1)\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumOrderedExponentials:\n",
    "    def __init__(self, number_states):\n",
    "        self.number_states = number_states\n",
    "\n",
    "    def __call__(self,t,p):\n",
    "        E = p[\"E0\"]\n",
    "        out = p[f\"A{0}\"] * np.exp( -t*E )\n",
    "    \n",
    "        for n in range(1,self.number_states):\n",
    "            #    ΔE_n = E_n - E_{n-1}\n",
    "            # =>  E_n = E_{n-1} + ΔE_n\n",
    "            E += p[f\"dE{n}\"]\n",
    "    \n",
    "            out += p[f\"A{n}\"] * np.exp( -t*E )\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_average_prior(fit_state, key, fit_task):\n",
    "    r\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # determine if we desire a log prior\n",
    "    log_prior = 'log' in key\n",
    "\n",
    "    # prepare the key to access the exponentiated result extracted of the model average\n",
    "    if log_prior:\n",
    "        key = key[4:-1]\n",
    "\n",
    "    # compute the model average\n",
    "    model_average = fit_state.model_average()\n",
    "\n",
    "    # ensure that the key is in the model average and if not return a flat prior\n",
    "    if key not in model_average['est'].keys():\n",
    "        raise RuntimeError(f\"{key} not yet fitted, choose different prior strategy\")\n",
    "\n",
    "    # prior rule: N( <p>, X*std(p) )\n",
    "    prior = gv.gvar(\n",
    "        model_average['est'][key],\n",
    "        #np.maximum(\n",
    "        #    Args['est'][\"A00\"],\n",
    "        model_average['err'][key] * fit_task[\"prior strategy\"][\"std scale\"]\n",
    "        #)\n",
    "    )\n",
    "\n",
    "    if log_prior:\n",
    "        return gv.log(prior)\n",
    "    else:\n",
    "        return prior\n",
    "\n",
    "\n",
    "def prior_sum_ordered_exponentials(NumberStates, q2, params, **kwargs):\n",
    "    prior = gv.BufferDict()\n",
    "\n",
    "    if f\"q2: {q2}\" in params[\"C2pt fit\"].keys():\n",
    "        fit_task = params[\"C2pt fit\"][f\"q2: {q2}\"]\n",
    "    else:\n",
    "        fit_task = params[\"C2pt fit\"][\"shared\"]    \n",
    "    \n",
    "    if \"fit_state\" in kwargs.keys():\n",
    "        fit_state = kwargs[\"fit_state\"]\n",
    "            \n",
    "        prior[\"A0\"] = model_average_prior(fit_state = fit_state, key = \"A0\", fit_task = fit_task)\n",
    "        prior[\"E0\"] = model_average_prior(fit_state = fit_state, key = \"E0\", fit_task = fit_task)\n",
    "        \n",
    "        for n in range(1,NumberStates):\n",
    "            for key in [f\"dE{n}\", f\"A{n}\"]:\n",
    "                if key not in fit_state.keys_all:\n",
    "                    prior[key] = gv.gvar(1,1000)\n",
    "                else:\n",
    "                    prior[key] = model_average_prior(fit_state = fit_state, key = key, fit_task = fit_task)\n",
    "                \n",
    "        return prior\n",
    "\n",
    "    linear_fit_result = one_state_solution[f\"q2: {q2}\"].result_params()\n",
    "    \n",
    "    prior[\"A0\"] = gv.gvar(\n",
    "               np.exp( gv.mean(linear_fit_result[\"est\"][\"ln(A0)\"])),\n",
    "        np.std(np.exp( gv.mean(linear_fit_result[\"res\"][\"ln(A0)\"])), axis =0 ) * fit_task[\"prior strategy\"][\"std scale\"]\n",
    "    )\n",
    "    prior[\"E0\"] = gv.gvar(\n",
    "        linear_fit_result[\"est\"][\"E0\"],\n",
    "        linear_fit_result[\"err\"][\"E0\"] * fit_task[\"prior strategy\"][\"std scale\"]\n",
    "    )\n",
    "\n",
    "    C = C2pt_unpolarized[q2]\n",
    "    C = gv.gvar( np.mean(C,axis=0), np.std(C,axis=0) ) \n",
    "\n",
    "    for n in range(1,NumberStates):\n",
    "        \n",
    "        if n == 1:\n",
    "            prior[f\"log(dE1)\"]= gv.log(gv.gvar(\n",
    "                gv.mean(prior[f\"E0\"] + fit_task[\"prior strategy\"][\"mpi\"]),\n",
    "                gv.mean(prior[f\"E0\"] + fit_task[\"prior strategy\"][\"mpi\"]),\n",
    "            ))\n",
    "\n",
    "            t_probe = 1\n",
    "            tmp = (C[t_probe] - prior[\"A0\"] * np.exp(-t_probe*prior[\"E0\"]) ) * np.exp( t_probe * ( prior[\"dE1\"] + prior[\"E0\"]) )\n",
    "            prior[f\"A1\"] = gv.gvar( \n",
    "                gv.mean(tmp),gv.mean(tmp)\n",
    "            )\n",
    "        else:\n",
    "            prior[f\"A{n}\"] = gv.gvar(1,1000)\n",
    "            prior[f\"log(dE{n})\"] = gv.log(gv.gvar(1,1))\n",
    "\n",
    "    return prior\n",
    "\n",
    "models = {\n",
    "    \"sum of ordered exponentials\": (SumOrderedExponentials, prior_sum_ordered_exponentials),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_C2pt(C2pt, q2, params, pbar):\n",
    "    if f\"q2: {q2}\" in params[\"C2pt fit\"].keys():\n",
    "        fit_task = params[\"C2pt fit\"][f\"q2: {q2}\"]\n",
    "    else:\n",
    "        fit_task = params[\"C2pt fit\"][\"shared\"]\n",
    "\n",
    "    fit_state = ca.FitState()\n",
    "\n",
    "    C = C2pt[q2] \n",
    "    \n",
    "    for number_states in range(1, fit_task[\"max number states\"]+1):\n",
    "        number_params = 2 * number_states\n",
    "\n",
    "        model = models[fit_task[\"model\"]][0](number_states)\n",
    "\n",
    "        num_fits = 0 \n",
    "        for ts in range(fit_task[\"min interval start\"], fit_task[\"interval end\"], fit_task[\"interval step\"]):\n",
    "            if (fit_task[\"interval end\"]-ts <= number_params+2 ): continue\n",
    "            \n",
    "            te = fit_task[\"interval end\"]\n",
    "\n",
    "            if num_fits > 4:\n",
    "                prior = models[fit_task[\"model\"]][1](number_states, q2, params, fit_state = fit_state)\n",
    "            else:\n",
    "                prior = models[fit_task[\"model\"]][1](number_states, q2, params)\n",
    "\n",
    "            if number_states == 1:\n",
    "                fit_result = ca.linear_regression(\n",
    "                    abscissa                = np.arange(ts,te),\n",
    "                    ordinate_est            = np.mean(np.log(np.abs(C[:,ts:te])), axis = 0),\n",
    "                    ordinate_std            = np.std (np.log(np.abs(C[:,ts:te])), axis = 0),\n",
    "                    ordinate_cov            = np.cov (np.log(np.abs(C[:,ts:te])), rowvar=False),\n",
    "                    resample_ordinate_est   = np.log(np.abs(C[:,ts:te])),\n",
    "                    resample_ordinate_std   = np.std (np.log(np.abs(C[:,ts:te])), axis = 0),\n",
    "                    resample_ordinate_cov   = np.cov (np.log(np.abs(C[:,ts:te])), rowvar=False),\n",
    "                    # fit strategy, default: only uncorrelated central value fit:\n",
    "                    central_value_fit            = fit_task[\"central value fit\"],\n",
    "                    central_value_fit_correlated = fit_task[\"central value fit correlated\"],\n",
    "                    resample_fit                 = fit_task[\"resample fit\"],\n",
    "                    resample_fit_correlated      = fit_task[\"resample fit correlated\"],\n",
    "                    resample_type               = \"bst\" if params[\"bootstrap\"] else \"jkn\",\n",
    "                    \n",
    "                    has_intercept = True,\n",
    "                    parameter_names = [\"E0\", \"log(A0)\"]\n",
    "                )\n",
    "                fit_result.fcn = SumOrderedExponentials(number_states = 1)\n",
    "                \n",
    "            else:\n",
    "                fit_result = ca.fit(\n",
    "                    abscissa                = np.arange(ts,te),\n",
    "                    ordinate_est            = np.mean(C[:,ts:te], axis = 0),\n",
    "                    ordinate_std            = np.std (C[:,ts:te], axis = 0),\n",
    "                    ordinate_cov            = np.cov (C[:,ts:te], rowvar=False),\n",
    "                    resample_ordinate_est   = C[:,ts:te],\n",
    "                    resample_ordinate_std   = np.std (C[:,ts:te], axis = 0),\n",
    "                    resample_ordinate_cov   = np.cov (C[:,ts:te], rowvar=False),\n",
    "                    # fit strategy, default: only uncorrelated central value fit:\n",
    "                    central_value_fit            = fit_task[\"central value fit\"],\n",
    "                    central_value_fit_correlated = fit_task[\"central value fit correlated\"],\n",
    "                    resample_fit                 = fit_task[\"resample fit\"],\n",
    "                    resample_fit_correlated      = fit_task[\"resample fit correlated\"],\n",
    "                    resample_fit_resample_prior  = fit_task[\"resample prior\"],\n",
    "                    resample_type               = \"bst\" if params[\"bootstrap\"] else \"jkn\",\n",
    "                    # args for lsqfit:\n",
    "                    model   = model,\n",
    "                    prior   = prior,\n",
    "                    p0      = None,\n",
    "                    svdcut  = None,\n",
    "                    maxiter = 10_000,\n",
    "                )\n",
    "\n",
    "            num_fits+=1\n",
    "\n",
    "            pbar.write(f\"{fit_result}\")\n",
    "\n",
    "            fit_state.append(fit_result)\n",
    "            pbar.update()\n",
    "        # end for ts\n",
    "    # end for number_states\n",
    "    return fit_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing the building block class instance...\n",
      "\n",
      "\n",
      "Looping over the configurations to read the building blocks from the h5 files...\n",
      "\n",
      "\n",
      "Looping over the configurations to read the 2-point correlators from the h5 files...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#folders where the dataset is\n",
    "p3fold = os.environ['mount_point_path'] + \"48c48/binned_1012_hmz370_BMW/3PointCorrelation/T6/\"\n",
    "p2fold = os.environ['mount_point_path'] + \"48c48/binned_1012_hmz370_BMW/2PointCorrelation/\"\n",
    "\n",
    "#instance of the building block class\n",
    "bb = bulding_block(p3fold,p2fold, maxConf=100, verbose=True, skip3p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.latticeT\n",
    "\n",
    "times = np.arange(bb.latticeT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 48)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2corr = bb.p2_corr.real\n",
    "\n",
    "np.shape(p2corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit parameters\n",
    "\n",
    "# abscissa = arange(t_start_plateau, t_end_plateau)\n",
    "\n",
    "# ordinate_est = mean(p2corr, axis=cfg )    #-----> everything performed on log of abs of p2corr, not p2corr itself, if regression is used instead of fit\n",
    "# ordinate_std = std(p2corr, axis=cfg ) \n",
    "# ordinate_cov = cov(p2corr, axis=cfg ) \n",
    "\n",
    "# resample_ordinate_est = p2corr #----------> axis 0 = cfg or axis 0 = resample ???\n",
    "# resample_ordinate_std = ordinate_std\n",
    "# resample_ordinate_cov = ordinate_cov\n",
    "\n",
    "# central_value fit = bool, related to type of fit (True by default)\n",
    "# central_value_fit_correlated = bool, related to type of fit (False by default)\n",
    "\n",
    "# resample_fit                 =  bool, related to type of fit (False by default)\n",
    "# resample_fit_correlated      =  bool, related to type of fit (False by default)\n",
    "\n",
    "# resample_fit_resample_prior  =  bool, related to type of fit (True by default) #----> might want to put that to False to make running time shorter while developing\n",
    "# resample_type               = \"bst\" if bootstrap is used else \"jkn\" if jackknife is used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params[\"C2pt fit\"] = {\n",
    "#    \"shared\": {\n",
    "#        \"min interval start\": 1,\n",
    "#        \"interval end\"      : 50,\n",
    "#        \"interval step\"     : 4,\n",
    "#        \n",
    "#        \"max number states\": 2,\n",
    "#        \"model\" : \"sum of ordered exponentials\",\n",
    "#        \n",
    "#        \"central value fit\": True,            \n",
    "#        \"central value fit correlated\": False, \n",
    "#        \"resample fit\": True,     \n",
    "#        \"resample fit correlated\": False,      \n",
    "#        \"resample prior\": False,\n",
    "#\n",
    "#        \"prior strategy\": {\n",
    "#            \"Eeff\": {\n",
    "#                \"estimate range start\": 15,\n",
    "#                \"estimate range stop\" : 50\n",
    "#            },\n",
    "#            \"std scale\": 3,\n",
    "#            \"mpi\": gv.gvar(\"0.09203(16)\")\n",
    "#        }\n",
    "#    }\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Central value fit requires ordinate_est (or resample_ordinate_est)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabscissa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace_folders/CorrelatorAnalyser/correlatoranalyser/fit.py:92\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(abscissa, ordinate_est, ordinate_std, ordinate_cov, resample_ordinate_est, resample_ordinate_std, resample_ordinate_cov, central_value_fit, central_value_fit_correlated, resample_fit, resample_fit_correlated, resample_fit_resample_prior, resample_type, model, prior, p0, svdcut, maxiter)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m central_value_fit:\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# We need ordinate data to fit against. \u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# We can either use provided ordinate_est or fit against the mean over resample_ordinate_est\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Check that at least one is provided\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ordinate_est \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resample_ordinate_est \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentral value fit requires ordinate_est (or resample_ordinate_est)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# In case a central value fit is desired check that covariance matrix is provided\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m central_value_fit_correlated \u001b[38;5;129;01mand\u001b[39;00m ordinate_cov \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Central value fit requires ordinate_est (or resample_ordinate_est)"
     ]
    }
   ],
   "source": [
    "ca.fit(abscissa=times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
